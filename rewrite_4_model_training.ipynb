{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import csv\n",
    "import cv2\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.applications.mobilenet import preprocess_input, MobileNet\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dev_image_generator(input_feed,data_folder, bs, mode=\"train\", aug=None):\n",
    "    index = 0\n",
    "    \n",
    "    NUM_IMAGES = len(input_feed)\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        # initialize our batches of images and labels\n",
    "        images = []\n",
    "        poly_cof = []\n",
    "        \n",
    "        # keep looping until we reach our batch size\n",
    "        while len(images) < bs:\n",
    "            \n",
    "            line = input_feed[index]\n",
    "            index = index + 1\n",
    "            if index >= len(input_feed):\n",
    "                index = 0;\n",
    "            \n",
    "            center_img_path = line[1]\n",
    "            file_name = center_img_path\n",
    "#             print('./{}/{}'.format(folder, file_name))\n",
    "            \n",
    "            if len(file_name) > 0:\n",
    "                image = cv2.imread('./{}/{}.jpg'.format(data_folder, file_name))\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                image = cv2.resize(image,(160,160))\n",
    "                \n",
    "            if image is not None:\n",
    "                pixels = np.asarray(image)\n",
    "                pixels = pixels.astype('float32')\n",
    "                pixels = pixels/255\n",
    "                images.append(pixels)\n",
    "#                 images.append(np.fliplr(image))\n",
    "            \n",
    "\n",
    "                x1 = (float(line[3])/127.5) -1\n",
    "                poly_cof.append([x1])\n",
    "        \n",
    "        # if the data augmentation object is not None, apply it\n",
    "        if aug is not None:\n",
    "            (images, labels) = next(aug.flow(np.array(images),\n",
    "                labels, batch_size=bs))\n",
    "        # yield the batch to the calling function\n",
    "        yield (np.array(images), np.array(poly_cof))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading all data and sepperate to train dataset and valdidate dataset ##\n",
    "\n",
    "image_load_data = []\n",
    "\n",
    "with open('dataset2.csv') as f:\n",
    "\n",
    "    next(f, None)\n",
    "\n",
    "    reader = csv.reader(f)\n",
    "    for csv_line in reader:\n",
    "        image_load_data.append((csv_line))\n",
    "\n",
    "image_load_data = shuffle(image_load_data)\n",
    "\n",
    "data_train, data_test  = train_test_split(image_load_data,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the number of epochs to train for and batch_size\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "data_folder = 'dataset'\n",
    "\n",
    "# initialize the total number of training and testing image\n",
    "NUM_TRAIN_IMAGES = len(data_train)\n",
    "NUM_TEST_IMAGES = len(data_test)\n",
    "\n",
    "trainGen = dev_image_generator(data_train,data_folder,BATCH_SIZE, mode = \"train\", aug = None)\n",
    "testGen = dev_image_generator(data_test,data_folder,BATCH_SIZE, mode = \"train\", aug = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize our Keras model and compile it\n",
    "\n",
    "base_model=MobileNet(input_shape=(160, 160, 3), alpha = 0.5,depth_multiplier = 1, dropout = 0.001,include_top = False, weights = \"imagenet\", classes = 1000, backend=keras.backend, layers=keras.layers,models=keras.models,utils=keras.utils)\n",
    "\n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(100,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "x=Dropout(0.1)(x)\n",
    "x=Dense(50,activation='relu')(x) #dense layer 3\n",
    "preds=Dense(1,activation='linear')(x) #final layer with softmax activation\n",
    "model=Model(inputs=base_model.input,outputs=preds)\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "filepath=\"w-imp-{epoch:02d}-{val_loss:.5f}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training w/ generator...\n",
      "Epoch 1/100\n",
      "300/300 [==============================] - 24s 81ms/step - loss: 2925.2510 - val_loss: 1056.7521\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1056.75208, saving model to w-imp-01-1056.75208.h5\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 19s 63ms/step - loss: 1266.8880 - val_loss: 2618.5068\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1056.75208\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 19s 64ms/step - loss: 862.0289 - val_loss: 1295.6703\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1056.75208\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 19s 64ms/step - loss: 719.9590 - val_loss: 1111.9783\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1056.75208\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 19s 64ms/step - loss: 588.9892 - val_loss: 1393.9788\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1056.75208\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 20s 65ms/step - loss: 532.0479 - val_loss: 392.5753\n",
      "\n",
      "Epoch 00006: val_loss improved from 1056.75208 to 392.57532, saving model to w-imp-06-392.57532.h5\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 22s 73ms/step - loss: 399.0591 - val_loss: 388.0228\n",
      "\n",
      "Epoch 00007: val_loss improved from 392.57532 to 388.02280, saving model to w-imp-07-388.02280.h5\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 22s 72ms/step - loss: 345.5826 - val_loss: 469.5695\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 388.02280\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 20s 68ms/step - loss: 339.6648 - val_loss: 937.2088\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 388.02280\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 21s 69ms/step - loss: 288.2838 - val_loss: 724.3886\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 388.02280\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 21s 69ms/step - loss: 292.1874 - val_loss: 411.4341\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 388.02280\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 22s 73ms/step - loss: 276.5668 - val_loss: 633.4490\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 388.02280\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 23s 76ms/step - loss: 279.4008 - val_loss: 555.5288\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 388.02280\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 20s 68ms/step - loss: 271.5426 - val_loss: 699.9219\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 388.02280\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 21s 71ms/step - loss: 255.5661 - val_loss: 508.6236\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 388.02280\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 21s 69ms/step - loss: 226.6483 - val_loss: 683.8779\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 388.02280\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 21s 71ms/step - loss: 244.4238 - val_loss: 834.2665\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 388.02280\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 21s 70ms/step - loss: 280.4412 - val_loss: 1609.5730\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 388.02280\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 21s 69ms/step - loss: 326.4288 - val_loss: 324.6601\n",
      "\n",
      "Epoch 00019: val_loss improved from 388.02280 to 324.66010, saving model to w-imp-19-324.66010.h5\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 21s 69ms/step - loss: 261.7926 - val_loss: 877.0271\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 324.66010\n",
      "Epoch 21/100\n",
      "195/300 [==================>...........] - ETA: 7s - loss: 214.6836"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-b59bca69f97c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m H = model.fit_generator(trainGen, steps_per_epoch=NUM_TRAIN_IMAGES // BATCH_SIZE, \n\u001b[0;32m      5\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtestGen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNUM_TEST_IMAGES\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                         epochs=NUM_EPOCHS, callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\yolo\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\yolo\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\yolo\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m                                             reset_metrics=False)\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\yolo\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\yolo\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3476\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\yolo\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "\n",
    "print(\"[INFO] training w/ generator...\")\n",
    "H = model.fit_generator(trainGen, steps_per_epoch=NUM_TRAIN_IMAGES // BATCH_SIZE, \n",
    "                        validation_data=testGen, validation_steps=NUM_TEST_IMAGES // BATCH_SIZE, \n",
    "                        epochs=NUM_EPOCHS, callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('road_following_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
